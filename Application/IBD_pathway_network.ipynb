{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBD data pathway score correlation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from process_met_data import ProcData\n",
    "from process_pathways import ProcessPathways\n",
    "import methods\n",
    "from simulate_met_data import SimulateDataset, SimulateDatasetNamed\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import helper_functs\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathway overlap/score correlation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Reactome pathway dictionary\n",
    "R76 = ProcessPathways(\"R76\", \"ChEBI2Reactome_All_Levels.txt\", \"Homo sapiens\")\n",
    "# R76 = ProcessPathways(\"R76\", \"Ensembl2Reactome.txt\", \"Homo sapiens\")\n",
    "pathway_dict, pathway_names = R76.process_reactome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = ['R-HSA-442660', 'R-HSA-1614635', 'R-HSA-352230', 'R-HSA-1614558', 'R-HSA-8963693', 'R-HSA-8957322', 'R-HSA-159418', 'R-HSA-192105', 'R-HSA-194068', 'R-HSA-193368', 'R-HSA-1660662', 'R-HSA-1369062', 'R-HSA-382556', 'R-HSA-9018678', 'R-HSA-9025106', 'R-HSA-9018683', 'R-HSA-351143', 'R-HSA-351202', 'R-HSA-2029480', 'R-HSA-2029485', 'R-HSA-211935', 'R-HSA-2162123', 'R-HSA-2142753']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = cluster1.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = [i for i in cluster1 if i != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2 =['R-HSA-70635', 'R-HSA-1222556', 'R-HSA-9006934', 'R-HSA-194138', 'R-HSA-392154', 'R-HSA-418346', 'R-HSA-4420097', 'R-HSA-5218920', 'R-HSA-73894', 'R-HSA-73929', 'R-HSA-73884', 'R-HSA-425397', 'R-HSA-15869', 'R-HSA-8956319', 'R-HSA-74259', 'R-HSA-83936', 'R-HSA-8956321', 'R-HSA-3296197', 'R-HSA-427601', 'R-HSA-196849', 'R-HSA-196854', 'R-HSA-428643', 'R-HSA-196807', 'R-HSA-197264', 'R-HSA-390696', 'R-HSA-5652084', 'R-HSA-71387']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2 = cluster2.split(\"\\n\")\n",
    "cluster2 = [i for i in cluster2 if i != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate overlaps\n",
    "c1_paths = {k: v for k, v in pathway_dict.items() if k in cluster1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate overlaps\n",
    "c2_paths = {k: v for k, v in pathway_dict.items() if k in cluster2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# path_coverage = {k: [i for i in v if i in compounds_present] for k, v in pathways_present.items()}\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "def overlap_coefficient(list1, list2):\n",
    "    # Szymkiewicz–Simpson coefficient\n",
    "    intersection = len(list(set(list1).intersection(list(set(list2)))))\n",
    "    smaller_set = min(len(list1), len(list2))\n",
    "    return float(intersection) / smaller_set\n",
    "\n",
    "# all_pathways = [k for k, v in path_coverage.items()]\n",
    "# jaccard_similarity_list = []\n",
    "# for pathway_pair in itertools.permutations(all_pathways,2):\n",
    "#     jaccard_similarity_list.append(jaccard_similarity(data[pathway_pair[0]], data[pathway_pair[1]]))\n",
    "\n",
    "all_pathways = cluster1\n",
    "rows = []\n",
    "\n",
    "for i in all_pathways:\n",
    "    curr_row = []\n",
    "    for p in all_pathways:\n",
    "        curr_row.append(jaccard_similarity(pathway_dict[i], pathway_dict[p]))\n",
    "    rows.append(curr_row)\n",
    "    \n",
    "r_ar = np.array(rows)\n",
    "j_df = pd.DataFrame(r_ar, index=all_pathways, columns=all_pathways)\n",
    "j_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation between pathway scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd_data = ProcData(\"IBD\")\n",
    "ibd_data.process_IBD(id_type=\"CHEBI\")\n",
    "ibd_data_orig = ibd_data.data_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Reactome pathway dictionary\n",
    "R76 = ProcessPathways(\"R76\", \"ChEBI2Reactome_All_Levels.txt\", \"Homo sapiens\")\n",
    "pathway_dict, pathway_names = R76.process_reactome()\n",
    "\n",
    "# Remove large and uninformative pathways\n",
    "# TODO Remove large and uninformative pathways\n",
    "remove_paths = [\"R-HSA-1430728\", \"R-HSA-1643685\", \"R-HSA-382551\"]\n",
    "pathway_dict = {k: v for k, v in pathway_dict.items() if k not in remove_paths}\n",
    "\n",
    "# Remove pathways not present in the dataset\n",
    "compounds_present = ibd_data_orig.columns.tolist()\n",
    "pathways_present = {k: v for k, v in pathway_dict.items() if len([i for i in compounds_present if i in v]) > 1}\n",
    "print(len(pathways_present))\n",
    "print(len(compounds_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd_data_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "def kpca_res(mat, pathways):\n",
    "    pathway_matrices = []\n",
    "    pathway_ids = []\n",
    "    for pathway, compounds in pathways.items():\n",
    "        single_pathway_matrix = mat.drop(mat.columns.difference(compounds), axis=1)\n",
    "        if single_pathway_matrix.shape[1] >= 1:\n",
    "            pathway_matrices.append(single_pathway_matrix.values)\n",
    "            pathway_ids.append(pathway)\n",
    "\n",
    "    scores = []\n",
    "    for n, m in enumerate(pathway_matrices):\n",
    "        kpca = KernelPCA(n_components=2, kernel=\"rbf\")\n",
    "        new_data = kpca.fit_transform(m)\n",
    "        scores.append(new_data[:, 0])\n",
    "    scores_df = pd.DataFrame(scores, columns=mat.index, index=pathways.keys())\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = kpca_res(ibd_data_orig.iloc[:, :-2], pathways_present).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = scores_df.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(corr_mat.values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(j_df.values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_adjacency(corr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nx.nodes(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, weights = zip(*nx.get_edge_attributes(G,'weight').items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all pathways\n",
    "size_dict = dict(zip(corr_mat.columns, [len(pathway_dict[i]) for i in corr_mat.columns]))\n",
    "nx.set_node_attributes(G, size_dict, \"pathway_size\")\n",
    "\n",
    "# add pathway name as a node attribute\n",
    "name_dict = dict(zip(corr_mat.columns, [pathway_names[i] for i in corr_mat.columns]))\n",
    "nx.set_node_attributes(G, name_dict, \"pathway_name\")\n",
    "\n",
    "# add cluster participation as a node attribute\n",
    "participation_dict = dict(zip(corr_mat.columns, [1 if i in cluster1 else 2 if i in cluster2  else 0 for i in corr_mat.columns]))\n",
    "nx.set_node_attributes(G, participation_dict, \"in_cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise pathway scores\n",
    "scores_df.iloc[:, :] = StandardScaler().fit_transform(scores_df.iloc[:, :].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fold changes \n",
    "scores_df[\"Group\"] = ibd_data_orig[\"Group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd_group_t = scores_df[scores_df[\"Group\"] == \"IBD\"].iloc[:, :-1]\n",
    "ctrl_group_t = scores_df[scores_df[\"Group\"] != \"IBD\"].iloc[:, :-1]\n",
    "fold_changes_t = np.mean(ibd_group_t, axis=0) - np.mean(ctrl_group_t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_changes_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mean fold change as a node attribute\n",
    "fc_dict = dict(zip(fold_changes_t.index, fold_changes_t))\n",
    "nx.set_node_attributes(G, fc_dict, \"mean_FC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pathway coverage as a node attribute\n",
    "compounds_present = ibd_data_orig.iloc[:, :-2].columns.tolist()\n",
    "pathways_present = {k: v for k, v in pathway_dict.items() if any(x in compounds_present for x in v)}\n",
    "path_coverage = {k: list(set(compounds_present) & set(v)) for k, v in pathways_present.items()}\n",
    "coverage_dict = dict(zip(path_coverage.keys(), [len(i) for i in path_coverage.values()]))\n",
    "nx.set_node_attributes(G, coverage_dict, \"coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add average score value based on subtype\n",
    "scores_df[\"diagnosis\"] = ibd_data_orig[\"IBD_status\"]\n",
    "cd_avg = np.mean(scores_df[scores_df[\"diagnosis\"] == \"CD\"].iloc[:, :-1], axis=0)\n",
    "uc_avg = np.mean(scores_df[scores_df[\"diagnosis\"] == \"UC\"].iloc[:, :-1], axis=0)\n",
    "ctrl_avg = np.mean(scores_df[scores_df[\"diagnosis\"] == \"nonIBD\"].iloc[:, :-1], axis=0)\n",
    "nx.set_node_attributes(G, cd_avg.to_dict(), \"CD_avg\")\n",
    "nx.set_node_attributes(G, uc_avg.to_dict(), \"UC_avg\")\n",
    "nx.set_node_attributes(G, ctrl_avg.to_dict(), \"CTRL_avg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pathway size as a node attribute\n",
    "size_dict = dict(zip(cluster1, [len(pathway_dict[i]) for i in cluster1]))\n",
    "nx.set_node_attributes(G, size_dict, \"pathway_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pathway name as a node attribute\n",
    "name_dict = dict(zip(cluster1, [pathway_names[i] for i in cluster1]))\n",
    "nx.set_node_attributes(G, name_dict, \"pathway_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[\"R-HSA-375280\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.get_node_attributes(G, \"pathway_name\").values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(G, \"IBD_subtype_avg_scores_kPCA_top50.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39]",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
